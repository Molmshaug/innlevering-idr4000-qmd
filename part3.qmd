# Deloppgave 3: Vitenskapsfilosofi

<!-- Part 3: Philosophy of science -->

## Falsifikasjonisme
*Hva er Poppers falsifiserbarhetskriterium og hvilket spørsmål skal dette kriterium gi svar på? Hvorfor mener andre vitenskapsfilosofer (f.eks. Okasha) at vi ikke trenger å svare på dette spørsmålet? Hvem synes dere har rett?*

Poppers falsifiserbarhetskriterium er basert på at en teori skal være falsifiserbar, men ikke falsifisert. Popper mente at dersom en teori skulle være vitenskapelig, måtte den også være mulig å avkrefte. Videre mente han at evidens som bekrefter en teori ikke eksisterer. Teorier som ble tilpasset data og som dermed ikke kunne motsies kalte Popper for «pseudo-science» («ikke-vitenskapelig vitenskap». Popper kritiserte Karl Marx og Sigmund Freud sine teorier for å være «ikke-vitenskapelige». Karl Marx sine teorier ble kritisert av Popper for å tilpasses underveis. Dersom teoriene møtte motstand igjennom en test eller gjennom data så kunne teorien endres for å tilpasse seg motstanden i dataen. På denne måten kunne Marx fremdeles beholde teorien sin. Popper mente at Freuds teorier ikke var mulig å teste eller falsifisere og beskrev de dermed som myter og ikke som vitenskap. Poppers falsifiserbarhetskriterium skulle derfor gi svar på om en teori er vitenskapelig eller ikke. Utfordringen med å skille mellom vitenskapelige og «ikke-vitenskapelige» teorier kalte Popper for demarkasjonsproblemet [@okasha_2016; @popper_conjectures_1969]. 

Flere filosofer har kritisert Poppers falsifiserbarhetskriterium for å være altfor forenklet. En av de er @okasha_2016 som skriver i Philosophy of Science: A Very Short Introduction at det er flere eksempler på det som Popper kalte for «pseudo-science» har ført til flere viktige vitenskapelige funn. For eksempel ved oppdagelsen av planeten Neptun. To forskere på midten av 1800-tallet John Couch Adams fra England og Urbain Leverrier fra Frankrike oppdaget planeten Neptun ved å gjøre nettopp det Popper kritiserte Marxister for å gjøre. Adams og Leverrier forsket videre til tross for at Newtons gravitasjonsteori var feil i spådommen om Uranus sin bane i verdensrommet. I likhet med Marx og Freud tilpasset Adams og Leverrier sin teori og konkluderte med at det måtte finnes en ny planet som ikke var enda var oppdaget. Neptun ble like etter oppdaget som bekreftet Newtons gravitasjonsteori nok en gang. [@okasha_2016]. Okasha mente med blant annet dette eksempelet at Poppers forsøk på å avgrense vitenskap fra «pseudo-vitenskap» ikke kan stemme. 
Jeg mener selv at Poppers falsifiserbarhetskriterium har hatt en stor verdi for vitenskapsteori. Det utfordrer til kritisk tenkning og filosofering med en enkel og forståelig metode. Videre mener jeg at Okasha har rett i at Poppers falsifiserbarhetskriterium blir for enkelt og at det i tilfeller mener jeg at det blir riktig og si at en teori alltid er feil eller gal [@okasha_2016]. Det finnes en slags objektivitet ved at en teori skal kunne falsifiseres, men at den viktigste forskjellen ligger i hvor godt eller dårlig en teori er bekreftet. Det vil ikke være riktig å avskrive enhver teori som møter litt motstand, men jeg mener det bør være en viss balanse mellom det å avkrefte og bekrefte teorier. Dette ville også avskrevet flere viktige vitenskapelige funn. Spørsmålet om vi skal benytte oss av Poppers falsifiserbarhetskriterium blir derfor erstattet av spørsmålet om teorier er gode eller dårlige og hvorvidt det finnes empirisk data og statistikk før å bekrefte eller avkrefte teorier.

##	Hypotetisk deduktiv metode og abduksjon
*Hva er strukturen på et bekreftende vitenskapelig argument ifølge den hypotetisk deduktive metode? Forklar ut fra Hempels artikkel, men bruk egne eksempel.*

Hypotetisk deduktiv metode (HD-metoden) starter med at vi formulerer en teori eller hypotese. Deretter deduserer vi empiriske konsekvenser som følge av teorien eller hypotesen som testes gjennom eksperiment eller empiriske observasjoner. Dersom deduksjonen viser seg å stemme bekreftes teorien induktivt, til en viss grad. Det sies at teorien bekreftes til viss grad på grunn av at teoriene aldri kan bekreftes til å være 100% sanne. @hempel_1966 beskriver dette med at fremtidig relevant data kan gi nye funn enn det som tidligere har kommet frem. Dette kan beskrives med et eksempel fra styrketrening. For å oppnå økt maksimal styrke er det bedre å trene med få repetisjoner og tunge vekter enn å trene med mange repetisjoner på en lettere vekt. Nåværende forskning viser at dette stemmer, men vi kan ikke bevise at dette er sant ved 100% av tilfellene. Det kan komme forskning frem i tid som viser helt andre resultater enn det vi har i dagens litteratur. Med en slik induktiv påstand vil vi aldri være helt sikker på at det stemmer, men økt vitenskap og mer forskning vil enten styrke eller svekke påstanden. På denne måten kommer vi også frem til svakhetene ved Hempel sin HD-metode.

Andre faktorer kan også påvirke resultatet til påstanden. For eksempel fysiske forutsetninger hos populasjonen det forskes på, forskjellig næringsinntak, søvnmengde og -rytme osv. Alle disse faktorene kan spille inn på effekten av styrketrening enten det er med tunge vekter og få repetisjoner eller om det er med lette vekter og mange repetisjoner. HD-metoden er alltid åpen for at det er andre forklaringer og slutter seg derfor bare til en teoris styrke eller svakhet ut fra det man har testet empirisk [@hempel_1966]. HD-metoden er også svak ved spørsmål om sannsynlighet eller prevalens, ettersom at det ikke er mulig å dedusere noe om frekvens. Et eksempel kan være kan være følgende teori: Sannsynligheten for å få et hoftebrudd øker i takt med alderen. Hvis man i dette tilfellet sier at sjansen for å få et hoftebrudd øker med 2% hvert år etter fylte 60 år så vil man i teorien ha en sannsynlighet for å få et hoftebrudd som øker lineært med alderen. Svakheten med HD-metoden i et slikt tilfelle er at det finnes flere teorier/faktorer som kan påvirke risikoen for å få et hoftebrudd enn bare økt alder, for eksempel aktivitetsstatus, kjønn, tidligere skadehistorikk og funksjonsnivå for å nevne noen. Dette kan påvirke frekvensen for å få hoftebrudd etter fylte 60 år slik at sannsynligheten ikke er slik at den økes 2% per år. I dette tilfellet tar ikke HD-metoden hensyn til at ulike faktorer kan påvirke dataen. 

Abduksjon er en annen teori som ligner den hypotetisk deduktive metoden. Abduksjon er også kjent som «slutning til den beste forklaringen». Den er ment å løse problemene til HD-metoden. Den logiske strukturen i abduksjon er lignende den i HD-metoden, men skiller seg fra at den slutter seg til den beste forklaringen. Den beste forklaringen anses å være god eller bedre når den enten forklarer flere forskjellige data, har høyere forklaringskraft, utgår fra færre årsaker/faktorer eller at den er tilsvarende en annen forklaring, men enklere. Abduksjon krever med andre ord at man sammenligner flere teorier for deretter å lande på den teorien som best forklarer teorien/hypotesen. Der abduksjon stiller flere teorier opp mot hverandre og sammenligner for å finne den teorien som passer best, tar HD-metoden kun for seg en teori om gangen for så å undersøke om dataen/funnet induktivt støtter teorien.

## Replikasjonskrisen
*Hva mener Alexander Bird er forklaringen til at mange resultat i noen vitenskaper ikke repliseres? Oppsummere Birds argument for dette. Sammenlign også Birds forklaring med noen av de andre forklaringene som Bird diskuterer i seksjon 4. Har Bird rett i at hans forklaring er bedre?*

@bird_2020 beskriver at vitenskapen innen psykologi og medisin har vært utsatt for en krise. En krise kalt replikasjonskrisen. Dette er fenomen der flere tidligere vitenskapelige studier er forsøkt replisert, men der resultatene ikke har stemt overens med tidligere studier. Årsaken har blitt forsøkt forklart ved å peke på dårlig gjennomførte studier, tvilsomme forskningspraksiser, at det finnes en bias mot å publisere negative resultater og til og med forfalskning av resultater. Replikasjonskrisen dreier seg også om frykten for å grave opp i tidligere artikler og kritisere disse, ettersom dette ville svekke tilliten til vitenskapen i offentligheten. 

Alexander Bird forklarer i sin artikkel i British Journal for the Philosophy of Science [@bird_2020] det han mener er en av utfordringene til at vitenskaper ikke repliseres. Bird mente at basisratefeilen (base rate fallacy) er en sannsynlig årsak til replikasjonskrisen. Han beskrev at basisratefeilen sannsynlig vil oppstå dersom man trekker en slutning om sannsynlighet for en gitt forekomst av et generelt fenomen. Feilen som gjøres er at man fokuserer spesifikt på resultatet av en test, men glemmer å ta over seg hvor hyppig forekomsten av gitt fenomen skjer uavhengig av testen som gjennomføres. Dette gir utslag på at en for eksempel konkluderer med at sannsynligheten for å få en sjelden sykdom er større enn det den i realiteten er, fordi man kan feiltolke falske positive eller falske negative resultater (type-I-feil og type-2-feil). I vitenskapen i dag er resultater typisk regnet som signifikant eller ikke signifikant basert på P-verdien. Grensen for P-verdien er som regel satt på 0.05 (5%) og blir en slags pekepinn på om noe er sant eller usant basert på om resultatet er over eller under grensen. P-verdien sier noe om sannsynligheten for at et resultat er falskt positivt (type-1-feil). Et problem med å bruke P-verdi er da kan man konkludere på en befolkning, men P-verdien i studiet vil bare si noe om utvalget som det forskes på. Type-2-feil, kalles også falsk negativ, og betyr at man forkaster en alternativ forklaring, selv om den egentlig stemmer. 

Av andre forklaringer som kan ha bidratt til replikasjonskrisen skriver @bird_2020 om at flere studier har lav statistisk, publiseringsbias og tvilsom forskningspraksis og svindel. Flere har kommet med forklaringen om at lav statistisk styrke er en av årsakene til replikasjonskrisen. Studier med få forsøkspersoner blir spesielt trukket frem, da det er vanskeligere å replisere resultater gjort på små populasjoner. Publiseringsbias eller publiseringsskjevhet er det at det er for mange studier med positive resultater er publisert, når man sammenligner med studier med negative resultater. Det er et stort press fra flere kanter som alle ønsker å publisere nye funn og positive resultater, og ikke negative resultater. Dette kan føre til økt ønske om å replisere studier med positive funn og at igjen kan øke forekomsten av at falske positive resultater blir publisert. Tvilsom forskningspraksis er også et av områdene det gjøres mye feil i. Dette kan være alt fra ubevisst skjevhet og p-hacking, der man leter bevisst etter positive resultater i egen studie, til helt bevisst forfalskning av data. Presset på å publisere er så høyt at dette kan føre til at forskningen gjennomføres etter standarden den burde. Det er også store økonomiske faktorer som påvirke ønsket om å publisere. Det kan være årsaker der større studier koster langt mer penger å gjennomføre og derfor tar man til takke med mindre studier og publiserer heller resultater og funn hyppigere.

Det er lett å si at Bird har rett til at basisratefeilen er en av årsakene til replikasjonskrisen. Dette er heller ikke hele årsaken da vi vet et at det finnes skjevhet der positive eller negative resultater ikke publiseres like ofte. Ønsket om å finne helt nye funn er så stort at forskere kan ignorere bevisst og ubevisst sannsynligheten for at de har falske positive resultater. Det er veldig mange studier som er gjennomført med lav statistisk styrke som følge av få forsøkspersoner, dette fører til at det er vanskelig å replisere disse studiene. Det økonomiske presset eller insentivene som finnes er også store, gjerne for å finne positive resultater, som kan gi disse resultatene for mye vekt, men også føre til økt hyppighet av forfalskning og svindel. 


	





